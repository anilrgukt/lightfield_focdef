{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.16"
    },
    "colab": {
      "name": "ulf_focdef_train.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kDAff5Wp2Pb",
        "colab_type": "text"
      },
      "source": [
        "###  **Module imports**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZeyhuVxPKJv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# coding: utf-8\n",
        "#get_ipython().magic(u'matplotlib inline')\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "from scipy import io\n",
        "from scipy import interpolate\n",
        "from scipy import ndimage\n",
        "from scipy.misc import imsave\n",
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ceazCDbqXW3",
        "colab_type": "text"
      },
      "source": [
        "###  **Hyperparameters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfbLaUSYPKJ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#parameters\n",
        "lfsize = [360, 540, 7, 7] #dimensions of Lytro light fields\n",
        "\n",
        "batchsize = 6 \n",
        "patchsize = [120, 120] #spatial dimensions of training light fields\n",
        "num_crops = 5 #number of random spatial crops per light field for each input queue thread to push\n",
        "\n",
        "test_batchsize = 8  \n",
        "test_patchsize = [210, 210]\n",
        "\n",
        "disp_mult = 10.0 #max disparity between adjacent views\n",
        "test_num_crops = 4\n",
        "\n",
        "learning_rate = 0.0001\n",
        "test = 1500\n",
        "train_iters = 100000\n",
        "test_iters = 75"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWMfNcGqqjYP",
        "colab_type": "text"
      },
      "source": [
        "###  **Defocus code**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVzu25fJPKJ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "defocus_code = np.ones([1,1,lfsize[2],lfsize[3],1]) # spatial blur kernel - uniform\n",
        "defocus_code = defocus_code[np.newaxis,:,:,:,:,:]/49.0\n",
        "\n",
        "blur_code = np.tile(defocus_code,(1,patchsize[0],patchsize[1],1,1,3))\n",
        "test_code = np.tile(defocus_code,(1,test_patchsize[0],test_patchsize[1],1,1,3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aprm7tYaqs8e",
        "colab_type": "text"
      },
      "source": [
        "###  **CNN layer functions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-KiEN6oPKJ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def weight_variable(w_shape, name):\n",
        "    return tf.get_variable(name, w_shape, initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
        "\n",
        "def bias_variable(b_shape, init_bias=0.0):\n",
        "    return tf.get_variable('bias', b_shape, initializer=tf.constant_initializer(init_bias))\n",
        "\n",
        "# No activation\n",
        "def cnn_layer_no_act(input_tensor, w_shape, b_shape, layer_name, is_training, rate=1, padding_type='SAME'):\n",
        "    with tf.variable_scope(layer_name):\n",
        "        W = weight_variable(w_shape, '_weights')\n",
        "        h = tf.nn.atrous_conv2d(input_tensor, W, rate, padding=padding_type, name=layer_name + '_conv')\n",
        "        h = h + bias_variable(b_shape)\n",
        "        return h\n",
        "    \n",
        "#standard atrous layer\n",
        "def cnn_layer(input_tensor, w_shape, b_shape, layer_name, is_training, rate=1, padding_type='SAME'):\n",
        "    with tf.variable_scope(layer_name):\n",
        "        W = weight_variable(w_shape, '_weights')\n",
        "        h = tf.nn.atrous_conv2d(input_tensor, W, rate, padding=padding_type, name=layer_name + '_conv')\n",
        "        h = h + bias_variable(b_shape)\n",
        "        h = tf.nn.elu(h)\n",
        "        h = tf.contrib.layers.batch_norm(h, scale=True, updates_collections=None, \n",
        "                                             is_training=is_training, scope=layer_name + '_bn')\n",
        "        return h\n",
        "    \n",
        "#standard strided layer\n",
        "def cnn_layer_strided(input_tensor, w_shape, b_shape, layer_name, is_training, stride=1, padding_type='SAME'):\n",
        "    with tf.variable_scope(layer_name):\n",
        "        W = weight_variable(w_shape, '_weights')\n",
        "        h = tf.nn.conv2d(input_tensor, W, strides=[1, stride, stride, 1], padding=padding_type, name=layer_name + '_conv')\n",
        "        h = h + bias_variable(b_shape)\n",
        "        h = tf.nn.elu(h)\n",
        "        h = tf.contrib.layers.batch_norm(h, scale=True, updates_collections=None, \n",
        "                                             is_training=is_training, scope=layer_name + '_bn')\n",
        "        return h\n",
        "    \n",
        "def cnn_layer_transposed(input_tensor, w_shape, b_shape, o_shape, layer_name, is_training, stride=1, padding_type='SAME'):\n",
        "    with tf.variable_scope(layer_name):\n",
        "        W = weight_variable(w_shape, '_weights')\n",
        "        h = tf.nn.conv2d_transpose(input_tensor, W,  o_shape, strides=[1, stride, stride, 1], padding=padding_type, name=layer_name + '_conv')\n",
        "        h = h + bias_variable(b_shape)\n",
        "        h = tf.nn.elu(h)\n",
        "        h = tf.contrib.layers.batch_norm(h, scale=True, updates_collections=None, \n",
        "                                             is_training=is_training, scope=layer_name + '_bn')\n",
        "        return h\n",
        "    \n",
        "#layer with no normalization or activation\n",
        "def cnn_layer_no_bn(input_tensor, w_shape, b_shape, layer_name, stride=1, padding_type='SAME'):\n",
        "    with tf.variable_scope(layer_name):\n",
        "        W = weight_variable(w_shape, '_weights')\n",
        "        h = tf.nn.conv2d(input_tensor, W, strides=[1, stride, stride, 1], padding=padding_type, name=layer_name + '_conv')\n",
        "        h = h + bias_variable(b_shape)\n",
        "        return h\n",
        "\n",
        "#layer with activation no batch norm\n",
        "def cnn_layer_act_nobn(input_tensor, w_shape, b_shape, layer_name, is_training, rate=1, padding_type='SAME'):\n",
        "    with tf.variable_scope(layer_name):\n",
        "        W = weight_variable(w_shape, '_weights')\n",
        "        h = tf.nn.atrous_conv2d(input_tensor, W, rate, padding=padding_type, name=layer_name + '_conv')\n",
        "        h = h + bias_variable(b_shape)\n",
        "        h = tf.nn.elu(h)\n",
        "        return h\n",
        "\n",
        "#transpose convolution with activation no batch norm\n",
        "def cnn_layer_tr_nobn(input_tensor, w_shape, b_shape, o_shape, layer_name, is_training, stride=1, padding_type='SAME'):\n",
        "    with tf.variable_scope(layer_name):\n",
        "        W = weight_variable(w_shape, '_weights')\n",
        "        h = tf.nn.conv2d_transpose(input_tensor, W,  o_shape, strides=[1, stride, stride, 1], padding=padding_type, name=layer_name + '_conv')\n",
        "        h = h + bias_variable(b_shape)\n",
        "        h = tf.nn.elu(h)\n",
        "        return h        \n",
        "    \n",
        "def res_sum(a1, a2, layer_name, is_training):\n",
        "    with tf.variable_scope(layer_name):\n",
        "        h = a1 + a2\n",
        "        h = tf.nn.elu(h)\n",
        "        #h = tf.contrib.layers.batch_norm(h, scale=True, updates_collections=None, \n",
        "        #                                     is_training=is_training, scope=layer_name + '_bn')\n",
        "        return h\n",
        "\n",
        "#transpose convolution with no activation no batch norm\n",
        "def cnn_layer_tr_nobn_noact(input_tensor, w_shape, b_shape, o_shape, layer_name, is_training, stride=1, padding_type='SAME'):\n",
        "    with tf.variable_scope(layer_name):\n",
        "        W = weight_variable(w_shape, '_weights')\n",
        "        h = tf.nn.conv2d_transpose(input_tensor, W,  o_shape, strides=[1, stride, stride, 1], padding=padding_type, name=layer_name + '_conv')\n",
        "        h = h + bias_variable(b_shape)\n",
        "        return h     \n",
        "    \n",
        "    \n",
        "#standard atrous layer\n",
        "def cnn_layer3D(input_tensor, w_shape, b_shape, layer_name, is_training, rate=[1, 1, 1, 1, 1], padding_type='SAME'):\n",
        "    with tf.variable_scope(layer_name):\n",
        "        W = weight_variable(w_shape, '_weights')\n",
        "        h = tf.nn.conv3d(input_tensor, W, strides=[1,1,1,1,1], padding=padding_type, \n",
        "                         name=layer_name + '_conv')\n",
        "        h = h + bias_variable(b_shape)\n",
        "        h = tf.nn.elu(h)\n",
        "        h = tf.contrib.layers.batch_norm(h, scale=True, updates_collections=None, \n",
        "                                             is_training=is_training, scope=layer_name + '_bn')\n",
        "        return h\n",
        "\n",
        "#3D convolution layer with no activation no batch norm\n",
        "def cnn_layer3D_no_bn(input_tensor, w_shape, b_shape, layer_name, padding_type='SAME'):\n",
        "    with tf.variable_scope(layer_name):\n",
        "        W = weight_variable(w_shape, '_weights')\n",
        "        h = tf.nn.conv3d(input_tensor, W, strides=[1,1,1,1,1], padding=padding_type, name=layer_name + '_conv')\n",
        "        h = h + bias_variable(b_shape)\n",
        "        return h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BP2-WZrNrYPC",
        "colab_type": "text"
      },
      "source": [
        "###  **Depth estimation network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaCNUUA2PKJ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def depth_network(x, xc, lfsize, disp_mult, is_training, name):\n",
        "    with tf.variable_scope(name):\n",
        "        \n",
        "        b_sz = tf.shape(x)[0]\n",
        "        y_sz = tf.shape(x)[1]\n",
        "        x_sz = tf.shape(x)[2]\n",
        "        v_sz = lfsize[2]\n",
        "        u_sz = lfsize[3]\n",
        "        \n",
        "        net_in = tf.concat([x,xc],axis=3)\n",
        "        c1 = cnn_layer(net_in, [3, 3, 6, 16], [16], 'c1', is_training)\n",
        "        c2 = cnn_layer(c1, [3, 3, 16, 64], [64], 'c2', is_training)\n",
        "        c3 = cnn_layer(c2, [3, 3, 64, 128], [128], 'c3', is_training)\n",
        "        c4 = cnn_layer(c3, [3, 3, 128, 128], [128], 'c4', is_training, rate=2)\n",
        "        c5 = cnn_layer(c4, [3, 3, 128, 128], [128], 'c5', is_training, rate=2)\n",
        "        c6 = cnn_layer(c5, [3, 3, 128, 128], [128], 'c6', is_training, rate=4)\n",
        "        c7 = cnn_layer(c6, [3, 3, 128, 128], [128], 'c7', is_training, rate=8)\n",
        "        c8 = cnn_layer(c7, [3, 3, 128, 64], [64], 'c8', is_training, rate=16)\n",
        "\n",
        "        sc1 = cnn_layer(c3, [3, 3, 128, 128], [128], 'sc1', is_training)\n",
        "        sc2 = cnn_layer(sc1, [3, 3, 128, 128], [128], 'sc2', is_training)\n",
        "        sc3 = cnn_layer(sc2, [3, 3, 128, 64], [64], 'sc3', is_training)\n",
        "        \n",
        "        dsc1 = cnn_layer(c6, [3, 3, 128, 64], [64], 'dsc1', is_training)\n",
        "        dsc2 = cnn_layer(dsc1, [3, 3, 64, 64], [64], 'dsc2', is_training)\n",
        "        \n",
        "        dsc3 = cnn_layer(c7, [3, 3, 128, 32], [32], 'dsc3', is_training)        \n",
        "        dsc4 = cnn_layer(dsc3, [3, 3, 32, 32], [32], 'dsc4', is_training)        \n",
        "        \n",
        "        dsc5 = cnn_layer(c8, [3, 3, 64, 32], [32], 'dsc5', is_training)        \n",
        "        dsc6 = cnn_layer(dsc5, [3, 3, 32, 32], [32], 'dsc6', is_training)        \n",
        "        \n",
        "        concat_feat = tf.concat([sc3,dsc2,dsc4,dsc6],axis=3)\n",
        "        \n",
        "        c13 = cnn_layer(concat_feat, [3, 3, 192, 128], [128], 'c13', is_training)\n",
        "        c14 = cnn_layer(c13, [3, 3, 128, 128], [128], 'c14', is_training)\n",
        "        c15 = cnn_layer(c14, [3, 3, 128, 49], [49], 'c15', is_training)\n",
        "        c12 = cnn_layer(c15, [3, 3, 49, 49], [49], 'c12', is_training)\n",
        "        c16 = cnn_layer(c12, [3, 3, 49, lfsize[2]*lfsize[3]], [lfsize[2]*lfsize[3]], 'c16', is_training)\n",
        "        c17 = disp_mult*tf.tanh(cnn_layer_no_bn(c16, [3, 3, lfsize[2]*lfsize[3], lfsize[2]*lfsize[3]], \n",
        "                                                [lfsize[2]*lfsize[3]], 'c10'))\n",
        "        #print tf.shape(c16), disp_mult\n",
        "        return tf.reshape(c17, [b_sz, y_sz, x_sz, v_sz, u_sz], name='rayd')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpZksBSPr1K4",
        "colab_type": "text"
      },
      "source": [
        "###  **Light field refinement network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mnnz8EhVPKJ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def occlusions_network3D_1(d, xc, shear, lfsize, is_training, name):\n",
        "    with tf.variable_scope(name):\n",
        "        \n",
        "        b_sz = tf.shape(d)[0]\n",
        "        y_sz = tf.shape(d)[1]\n",
        "        x_sz = tf.shape(d)[2]\n",
        "        v_sz = lfsize[2]\n",
        "        u_sz = lfsize[3]\n",
        "        \n",
        "        #depth\n",
        "        d = tf.tile(tf.expand_dims(d,5), [1,1,1,1,1,3])\n",
        "        d = tf.reshape(d, [b_sz, y_sz, x_sz, v_sz*u_sz, 3])\n",
        "        \n",
        "        #light field\n",
        "        x = tf.reshape(shear, [b_sz, y_sz, x_sz, v_sz*u_sz, 3])\n",
        "        #defocused image\n",
        "        xc = tf.expand_dims(xc,3)\n",
        "        #concatenating light field, depth and coded image as input to the network\n",
        "        xdc = tf.concat([x, d, xc],axis=3)\n",
        "        \n",
        "        \n",
        "        xdc = tf.transpose(xdc, [0, 4, 1, 2, 3]) # B, C, H, W, 2*v*u + 1\n",
        "        #shear = tf.reshape(shear, [b_sz, y_sz, x_sz, v_sz*u_sz*3])\n",
        "        #[filter_depth, filter_height, filter_width, in_channels, out_channels]\n",
        "        c1 = cnn_layer3D(xdc, [3,3,3,99,98], [98], 'c1', is_training, padding_type='SAME')\n",
        "        c2 = cnn_layer3D(c1, [3,3,3,98,98], [98], 'c2', is_training, padding_type='SAME')\n",
        "        c3 = cnn_layer3D(c2, [3,3,3,98,98], [98], 'c3', is_training, padding_type='SAME')\n",
        "        c4 = cnn_layer3D(c3, [3,3,3,98,49], [49], 'c4', is_training, padding_type='SAME')\n",
        "        c5 = cnn_layer3D(c4, [3,3,3,49,49], [49], 'c5', is_training, padding_type='SAME')\n",
        "        c6 = cnn_layer3D_no_bn(c5, [3, 3, 3, v_sz*u_sz, v_sz*u_sz], [v_sz*u_sz], 'c6', padding_type='SAME')\n",
        "        # o - b,3,h,w,49\n",
        "        c7 = tf.transpose(tf.reshape(c6, [b_sz, 3, y_sz, x_sz, v_sz, u_sz]), [0, 2, 3, 4, 5, 1])\n",
        "        c8 = tf.sigmoid(c7 + shear)\n",
        "        \n",
        "        return tf.reshape(c8, [b_sz, y_sz, x_sz, v_sz, u_sz, 3]), c7"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bNOSjxBPKKC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def occlusions_network3D_2(d, xc, shear, lfsize, is_training, name):\n",
        "    with tf.variable_scope(name):\n",
        "        \n",
        "        b_sz = tf.shape(d)[0]\n",
        "        y_sz = tf.shape(d)[1]\n",
        "        x_sz = tf.shape(d)[2]\n",
        "        v_sz = lfsize[2]\n",
        "        u_sz = lfsize[3]\n",
        "        \n",
        "        d = tf.tile(tf.expand_dims(d,5), [1,1,1,1,1,3])\n",
        "        d = tf.reshape(d, [b_sz, y_sz, x_sz, v_sz*u_sz, 3])\n",
        "        \n",
        "        x = tf.reshape(shear, [b_sz, y_sz, x_sz, v_sz*u_sz, 3])\n",
        "        \n",
        "        xc = tf.expand_dims(xc,3)\n",
        "        xdc = tf.concat([x, d, xc],axis=3)\n",
        "        \n",
        "        \n",
        "        xdc = tf.transpose(xdc, [0, 4, 1, 2, 3]) # B, C, H, W, 2*v*u + 1\n",
        "        #shear = tf.reshape(shear, [b_sz, y_sz, x_sz, v_sz*u_sz*3])\n",
        "        #[filter_depth, filter_height, filter_width, in_channels, out_channels]\n",
        "        c1 = cnn_layer3D(xdc, [3,3,3,99,98], [98], 'c1', is_training, padding_type='SAME')\n",
        "        c2 = cnn_layer3D(c1, [3,3,3,98,98], [98], 'c2', is_training, padding_type='SAME')\n",
        "        c3 = cnn_layer3D(c2, [3,3,3,98,49], [49], 'c3', is_training, padding_type='SAME')\n",
        "        c6 = cnn_layer3D_no_bn(c3, [3, 3, 3, v_sz*u_sz, v_sz*u_sz], [v_sz*u_sz], 'c6', padding_type='SAME')\n",
        "        # o - b,3,h,w,49\n",
        "        c7 = tf.transpose(tf.reshape(c6, [b_sz, 3, y_sz, x_sz, v_sz, u_sz]), [0, 2, 3, 4, 5, 1])\n",
        "        c8 = tf.sigmoid(c7 + shear)\n",
        "        \n",
        "        return tf.reshape(c8, [b_sz, y_sz, x_sz, v_sz, u_sz, 3])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrXoK5sPsGkX",
        "colab_type": "text"
      },
      "source": [
        "###  **Pipeline**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnAlkxN0PKKF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#full forward model\n",
        "def forward_model(x, xc, lf_batch, lfsize, shear_values, disp_mult, is_training):\n",
        "    try:\n",
        "        with tf.variable_scope('forward_model', reuse=None) as scope:\n",
        "            \n",
        "            #predict ray depths from input image and coded image\n",
        "            ray_depths = depth_network(x, xc, lfsize, disp_mult, is_training, 'ray_depths')\n",
        "\n",
        "            #shear input image by predicted ray depths to render Lambertian light field\n",
        "            lf_shear_r = depth_rendering(x[:,:,:,0], ray_depths, lfsize)\n",
        "            lf_shear_g = depth_rendering(x[:,:,:,1], ray_depths, lfsize)\n",
        "            lf_shear_b = depth_rendering(x[:,:,:,2], ray_depths, lfsize)\n",
        "            lf_shear = tf.stack([lf_shear_r, lf_shear_g, lf_shear_b], axis=5)\n",
        "            \n",
        "            #refocusing light field at a different depth\n",
        "            #shear_vals = np.random.uniform(-1.8,-0.35, 0.35, 1,batchsize)\n",
        "            lf_shear_ref,_ = refocus(lf_shear, batchsize, shift_tf=shear_values)\n",
        "            lf_ref,_ = refocus(lf_batch, batchsize, shift_tf=shear_values)\n",
        "            \n",
        "            #occlusion/non-Lambertian prediction network\n",
        "            d = tf.stop_gradient(ray_depths)\n",
        "            lfs = tf.stop_gradient(lf_shear)\n",
        "            y = occlusions_network3D_2(d, xc, lfs, lfsize, is_training, 'occlusions')\n",
        "            \n",
        "            return ray_depths, lf_shear, y, lf_ref, lf_shear_ref\n",
        "    except ValueError:\n",
        "        with tf.variable_scope('forward_model', reuse=True) as scope:\n",
        "            \n",
        "            #predict ray depths from input image and coded image\n",
        "            ray_depths = depth_network(x, xc, lfsize, disp_mult, is_training, 'ray_depths')\n",
        "\n",
        "            #shear input image by predicted ray depths to render Lambertian light field\n",
        "            lf_shear_r = depth_rendering(x[:,:,:,0], ray_depths, lfsize)\n",
        "            lf_shear_g = depth_rendering(x[:,:,:,1], ray_depths, lfsize)\n",
        "            lf_shear_b = depth_rendering(x[:,:,:,2], ray_depths, lfsize)\n",
        "            lf_shear = tf.stack([lf_shear_r, lf_shear_g, lf_shear_b], axis=5)\n",
        "            \n",
        "            #regularization loss with focal plane variation \n",
        "            lf_shear_ref = lf_shear\n",
        "            lf_ref = lf_shear\n",
        "            \n",
        "            #occlusion/non-Lambertian prediction network\n",
        "            d = tf.stop_gradient(ray_depths)\n",
        "            lfs = tf.stop_gradient(lf_shear)\n",
        "            y = occlusions_network3D_2(d, xc, lfs, lfsize, is_training, 'occlusions')\n",
        "            \n",
        "            return ray_depths, lf_shear, y, lf_ref, lf_shear_ref"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ks3jsRDZtShY",
        "colab_type": "text"
      },
      "source": [
        "###  **Refocusing light field**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9PrfkMjPKKH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def refocus_lf(lf, shifts, b_sz):\n",
        "    with tf.variable_scope('refocus_lf') as scope:\n",
        "        #b_sz = tf.shape(lf)[0]\n",
        "        y_sz = tf.shape(lf)[1]\n",
        "        x_sz = tf.shape(lf)[2]\n",
        "        u_sz = lfsize[2]\n",
        "        v_sz = lfsize[3]\n",
        "        \n",
        "        #create and reparameterize light field grid\n",
        "        b_vals = tf.to_float(tf.range(b_sz))\n",
        "        v_vals = tf.to_float(tf.range(v_sz)) - tf.to_float(v_sz/2)\n",
        "        u_vals = tf.to_float(tf.range(u_sz)) - tf.to_float(u_sz/2)\n",
        "        y_vals = tf.to_float(tf.range(y_sz))\n",
        "        x_vals = tf.to_float(tf.range(x_sz))\n",
        "    \n",
        "        b, y, x, v, u = tf.meshgrid(b_vals, y_vals, x_vals, v_vals, u_vals, indexing='ij')\n",
        "        #warp coordinates by ray depths\n",
        "        y_t = y - v * shifts*tf.ones_like(lf)\n",
        "        x_t = x - u * shifts*tf.ones_like(lf)\n",
        "        \n",
        "        v_r = v + tf.to_float(v_sz/2)\n",
        "        u_r = u + tf.to_float(u_sz/2)\n",
        "        \n",
        "        #indices for linear interpolation\n",
        "        b_1 = tf.to_int32(b)\n",
        "        y_1 = tf.to_int32(tf.floor(y_t))\n",
        "        y_2 = y_1 + 1\n",
        "        x_1 = tf.to_int32(tf.floor(x_t))\n",
        "        x_2 = x_1 + 1\n",
        "        v_1 = tf.to_int32(v_r)\n",
        "        u_1 = tf.to_int32(u_r)\n",
        "        \n",
        "        y_1 = tf.clip_by_value(y_1, 0, y_sz-1)\n",
        "        y_2 = tf.clip_by_value(y_2, 0, y_sz-1)\n",
        "        x_1 = tf.clip_by_value(x_1, 0, x_sz-1)\n",
        "        x_2 = tf.clip_by_value(x_2, 0, x_sz-1)\n",
        "        \n",
        "        #assemble interpolation indices\n",
        "        interp_pts_1 = tf.stack([b_1, y_1, x_1, v_1, u_1], -1)\n",
        "        interp_pts_2 = tf.stack([b_1, y_2, x_1, v_1, u_1], -1)\n",
        "        interp_pts_3 = tf.stack([b_1, y_1, x_2, v_1, u_1], -1)\n",
        "        interp_pts_4 = tf.stack([b_1, y_2, x_2, v_1, u_1], -1)\n",
        "        \n",
        "        #gather light fields to be interpolated\n",
        "        lf_1 = tf.gather_nd(lf, interp_pts_1)\n",
        "        lf_2 = tf.gather_nd(lf, interp_pts_2)\n",
        "        lf_3 = tf.gather_nd(lf, interp_pts_3)\n",
        "        lf_4 = tf.gather_nd(lf, interp_pts_4)\n",
        "        \n",
        "        #calculate interpolation weights\n",
        "        y_1_f = tf.to_float(y_1)\n",
        "        x_1_f = tf.to_float(x_1)\n",
        "        d_y_1 = 1.0 - (y_t - y_1_f)\n",
        "        d_y_2 = 1.0 - d_y_1\n",
        "        d_x_1 = 1.0 - (x_t - x_1_f)\n",
        "        d_x_2 = 1.0 - d_x_1\n",
        "        \n",
        "        w1 = d_y_1 * d_x_1\n",
        "        w2 = d_y_2 * d_x_1\n",
        "        w3 = d_y_1 * d_x_2\n",
        "        w4 = d_y_2 * d_x_2\n",
        "        \n",
        "        refocus_lf = tf.add_n([w1*lf_1, w2*lf_2, w3*lf_3, w4*lf_4])\n",
        "                        \n",
        "    return refocus_lf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bM9X8IIPKKK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#render light field from input image and ray depths by backward warping\n",
        "def depth_rendering(central, ray_depths, lfsize):\n",
        "    with tf.variable_scope('depth_rendering') as scope:\n",
        "        b_sz = tf.shape(central)[0]\n",
        "        y_sz = tf.shape(central)[1]\n",
        "        x_sz = tf.shape(central)[2]\n",
        "        u_sz = lfsize[2]\n",
        "        v_sz = lfsize[3]\n",
        "        \n",
        "        central = tf.expand_dims(tf.expand_dims(central, 3), 4)\n",
        "                                                \n",
        "        #create and reparameterize light field grid\n",
        "        b_vals = tf.to_float(tf.range(b_sz))\n",
        "        v_vals = tf.to_float(tf.range(v_sz)) - tf.to_float(v_sz/2)\n",
        "        u_vals = tf.to_float(tf.range(u_sz)) - tf.to_float(u_sz/2)\n",
        "        y_vals = tf.to_float(tf.range(y_sz))\n",
        "        x_vals = tf.to_float(tf.range(x_sz))\n",
        "    \n",
        "        b, y, x, v, u = tf.meshgrid(b_vals, y_vals, x_vals, v_vals, u_vals, indexing='ij')\n",
        "               \n",
        "        #warp coordinates by ray depths\n",
        "        y_t = y + v * ray_depths\n",
        "        x_t = x + u * ray_depths\n",
        "        \n",
        "        v_r = tf.zeros_like(b)\n",
        "        u_r = tf.zeros_like(b)\n",
        "        \n",
        "        #indices for linear interpolation\n",
        "        b_1 = tf.to_int32(b)\n",
        "        y_1 = tf.to_int32(tf.floor(y_t))\n",
        "        y_2 = y_1 + 1\n",
        "        x_1 = tf.to_int32(tf.floor(x_t))\n",
        "        x_2 = x_1 + 1\n",
        "        v_1 = tf.to_int32(v_r)\n",
        "        u_1 = tf.to_int32(u_r)\n",
        "        \n",
        "        y_1 = tf.clip_by_value(y_1, 0, y_sz-1)\n",
        "        y_2 = tf.clip_by_value(y_2, 0, y_sz-1)\n",
        "        x_1 = tf.clip_by_value(x_1, 0, x_sz-1)\n",
        "        x_2 = tf.clip_by_value(x_2, 0, x_sz-1)\n",
        "        \n",
        "        #assemble interpolation indices\n",
        "        interp_pts_1 = tf.stack([b_1, y_1, x_1, v_1, u_1], -1)\n",
        "        interp_pts_2 = tf.stack([b_1, y_2, x_1, v_1, u_1], -1)\n",
        "        interp_pts_3 = tf.stack([b_1, y_1, x_2, v_1, u_1], -1)\n",
        "        interp_pts_4 = tf.stack([b_1, y_2, x_2, v_1, u_1], -1)\n",
        "        \n",
        "        #gather light fields to be interpolated\n",
        "        lf_1 = tf.gather_nd(central, interp_pts_1)\n",
        "        lf_2 = tf.gather_nd(central, interp_pts_2)\n",
        "        lf_3 = tf.gather_nd(central, interp_pts_3)\n",
        "        lf_4 = tf.gather_nd(central, interp_pts_4)\n",
        "        \n",
        "        #calculate interpolation weights\n",
        "        y_1_f = tf.to_float(y_1)\n",
        "        x_1_f = tf.to_float(x_1)\n",
        "        d_y_1 = 1.0 - (y_t - y_1_f)\n",
        "        d_y_2 = 1.0 - d_y_1\n",
        "        d_x_1 = 1.0 - (x_t - x_1_f)\n",
        "        d_x_2 = 1.0 - d_x_1\n",
        "        \n",
        "        w1 = d_y_1 * d_x_1\n",
        "        w2 = d_y_2 * d_x_1\n",
        "        w3 = d_y_1 * d_x_2\n",
        "        w4 = d_y_2 * d_x_2\n",
        "        \n",
        "        lf = tf.add_n([w1*lf_1, w2*lf_2, w3*lf_3, w4*lf_4])\n",
        "                        \n",
        "    return lf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxCfa4AKPKKM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#resample ray depths for depth consistency regularization\n",
        "def transform_ray_depths(ray_depths, u_step, v_step, lfsize):\n",
        "    with tf.variable_scope('transform_ray_depths') as scope:\n",
        "        b_sz = tf.shape(ray_depths)[0]\n",
        "        y_sz = tf.shape(ray_depths)[1]\n",
        "        x_sz = tf.shape(ray_depths)[2]\n",
        "        u_sz = lfsize[2]\n",
        "        v_sz = lfsize[3]\n",
        "                                                        \n",
        "        #create and reparameterize light field grid\n",
        "        b_vals = tf.to_float(tf.range(b_sz))\n",
        "        v_vals = tf.to_float(tf.range(v_sz)) - tf.to_float(v_sz/2)\n",
        "        u_vals = tf.to_float(tf.range(u_sz)) - tf.to_float(u_sz/2)\n",
        "        y_vals = tf.to_float(tf.range(y_sz))\n",
        "        x_vals = tf.to_float(tf.range(x_sz))\n",
        "    \n",
        "        b, y, x, v, u = tf.meshgrid(b_vals, y_vals, x_vals, v_vals, u_vals, indexing='ij')\n",
        "               \n",
        "        #warp coordinates by ray depths\n",
        "        y_t = y + v_step * ray_depths\n",
        "        x_t = x + u_step * ray_depths\n",
        "        \n",
        "        v_t = v - v_step + tf.to_float(v_sz/2)\n",
        "        u_t = u - u_step + tf.to_float(u_sz/2)\n",
        "        \n",
        "        #indices for linear interpolation\n",
        "        b_1 = tf.to_int32(b)\n",
        "        y_1 = tf.to_int32(tf.floor(y_t))\n",
        "        y_2 = y_1 + 1\n",
        "        x_1 = tf.to_int32(tf.floor(x_t))\n",
        "        x_2 = x_1 + 1\n",
        "        v_1 = tf.to_int32(v_t)\n",
        "        u_1 = tf.to_int32(u_t)\n",
        "        \n",
        "        y_1 = tf.clip_by_value(y_1, 0, y_sz-1)\n",
        "        y_2 = tf.clip_by_value(y_2, 0, y_sz-1)\n",
        "        x_1 = tf.clip_by_value(x_1, 0, x_sz-1)\n",
        "        x_2 = tf.clip_by_value(x_2, 0, x_sz-1)\n",
        "        v_1 = tf.clip_by_value(v_1, 0, v_sz-1)\n",
        "        u_1 = tf.clip_by_value(u_1, 0, u_sz-1)\n",
        "        \n",
        "        #assemble interpolation indices\n",
        "        interp_pts_1 = tf.stack([b_1, y_1, x_1, v_1, u_1], -1)\n",
        "        interp_pts_2 = tf.stack([b_1, y_2, x_1, v_1, u_1], -1)\n",
        "        interp_pts_3 = tf.stack([b_1, y_1, x_2, v_1, u_1], -1)\n",
        "        interp_pts_4 = tf.stack([b_1, y_2, x_2, v_1, u_1], -1)\n",
        "        \n",
        "        #gather light fields to be interpolated\n",
        "        lf_1 = tf.gather_nd(ray_depths, interp_pts_1)\n",
        "        lf_2 = tf.gather_nd(ray_depths, interp_pts_2)\n",
        "        lf_3 = tf.gather_nd(ray_depths, interp_pts_3)\n",
        "        lf_4 = tf.gather_nd(ray_depths, interp_pts_4)\n",
        "        \n",
        "        #calculate interpolation weights\n",
        "        y_1_f = tf.to_float(y_1)\n",
        "        x_1_f = tf.to_float(x_1)\n",
        "        d_y_1 = 1.0 - (y_t - y_1_f)\n",
        "        d_y_2 = 1.0 - d_y_1\n",
        "        d_x_1 = 1.0 - (x_t - x_1_f)\n",
        "        d_x_2 = 1.0 - d_x_1\n",
        "        \n",
        "        w1 = d_y_1 * d_x_1\n",
        "        w2 = d_y_2 * d_x_1\n",
        "        w3 = d_y_1 * d_x_2\n",
        "        w4 = d_y_2 * d_x_2\n",
        "        \n",
        "        lf = tf.add_n([w1*lf_1, w2*lf_2, w3*lf_3, w4*lf_4])\n",
        "                        \n",
        "    return lf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mo06TKUcta2r",
        "colab_type": "text"
      },
      "source": [
        "###  **Loss functions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbQB_yhHPKKO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#loss to encourage consistency of ray depths corresponding to same scene point\n",
        "def fn_depth_consistency_loss(x, lfsize):\n",
        "    x_u = transform_ray_depths(x, 1.0, 0.0, lfsize)\n",
        "    x_v = transform_ray_depths(x, 0.0, 1.0, lfsize)\n",
        "    x_uv = transform_ray_depths(x, 1.0, 1.0, lfsize)\n",
        "    d1 = (x[:,:,:,1:,1:]-x_u[:,:,:,1:,1:])\n",
        "    d2 = (x[:,:,:,1:,1:]-x_v[:,:,:,1:,1:])\n",
        "    d3 = (x[:,:,:,1:,1:]-x_uv[:,:,:,1:,1:])\n",
        "    l1 = tf.reduce_mean(tf.abs(d1)+tf.abs(d2)+tf.abs(d3))\n",
        "    return l1\n",
        "\n",
        "def gradient(img):\n",
        "    gx = img[:,:,:-1,:] - img[:,:,1:,:]\n",
        "    gy = img[:,:-1,:,:] - img[:,1:,:,:]\n",
        "\n",
        "    return gx, gy\n",
        "\n",
        "#spatial TV loss (l1 of spatial derivatives)\n",
        "def fn_tv_loss(x):\n",
        "    temp = x[:,0:patchsize[0]-1,0:patchsize[1]-1,:,:]\n",
        "    dy = (x[:,1:patchsize[0],0:patchsize[1]-1,:,:] - temp)\n",
        "    dx = (x[:,0:patchsize[0]-1,1:patchsize[1],:,:] - temp)\n",
        "    l1 = tf.reduce_mean(tf.abs(dy)+tf.abs(dx))\n",
        "    return l1\n",
        "\n",
        "def fn_grad_loss(depths, lf):\n",
        "    b_sz = tf.shape(depths)[0]\n",
        "    y_sz = tf.shape(depths)[1]\n",
        "    x_sz = tf.shape(depths)[2]\n",
        "    u_sz = lfsize[2]\n",
        "    v_sz = lfsize[3]\n",
        "    # reshape depths of [B,h,w,v,u]\n",
        "    depths = tf.reshape(tf.transpose(depths, [0,3,4,1,2]), [b_sz*v_sz*u_sz, y_sz, x_sz])\n",
        "    depth_imgs = tf.expand_dims(depths, 3)\n",
        "    \n",
        "    lf_imgs = tf.reshape(tf.transpose(lf, [0,3,4,1,2,5]), [b_sz*v_sz*u_sz, y_sz, x_sz, 3])\n",
        "    d_gx, d_gy = gradient(depth_imgs) # b,h,w,1\n",
        "    l_gx, l_gy = gradient(lf_imgs)  # b,h,w,3\n",
        "    w_gx = tf.exp(-tf.reduce_mean(tf.abs(l_gx), 3, keep_dims=True))\n",
        "    w_gy = tf.exp(-tf.reduce_mean(tf.abs(l_gy), 3, keep_dims=True))\n",
        "    \n",
        "    smooth_gx = w_gx*tf.abs(d_gx)\n",
        "    smooth_gy = w_gy*tf.abs(d_gy)\n",
        "    return tf.reduce_mean(smooth_gx[:,:-1,:,:] + smooth_gy[:,:,:-1,:])\n",
        "\n",
        "#normalize to between -1 and 1, given input between 0 and 1\n",
        "def normalize_lf(lf):\n",
        "    return lf#2.0*(lf-0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKZO-MEdPKKR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_corners(data):\n",
        "    b_sz  = tf.shape(data)[0]\n",
        "    y_sz  = tf.shape(data)[1]\n",
        "    x_sz  = tf.shape(data)[2]\n",
        "    c_sz = tf.shape(data)[5]\n",
        "    \n",
        "    tl = data[:,:,:,0:1,0:1,:]\n",
        "    bl = data[:,:,:,6:,0:1,:]\n",
        "    tr = data[:,:,:,0:1,6:,:]\n",
        "    br = data[:,:,:,6:,6:,:]\n",
        "    cat_data = tf.concat([tl,tr,bl,br],3)\n",
        "    cat_data = tf.reshape(cat_data, [b_sz, y_sz, x_sz, 2, 2, c_sz])\n",
        "    #print cat_data.get_shape()\n",
        "    return tf.squeeze(cat_data)\n",
        "\n",
        "def get_shear_vals(shift):\n",
        "    bsz = shift.shape[0]\n",
        "    shear_vals = []\n",
        "    for i in range(bsz):\n",
        "        p = np.random.uniform(0,1,1)[0]\n",
        "        if p<0.56:\n",
        "            tmp = np.random.uniform(-1.15,-0.81,1)[0]\n",
        "            shear_vals.append(tmp)\n",
        "        else:\n",
        "            tmp = np.random.uniform(0.35,0.55,1)[0]\n",
        "            shear_vals.append(tmp)\n",
        "            \n",
        "    new_shift = tf.convert_to_tensor(shear_vals, dtype=tf.float32)\n",
        "    \n",
        "    return new_shift\n",
        "\n",
        "\n",
        "def get_rival_shifts(shift):\n",
        "    b_sz = shift.shape[0]\n",
        "    new_shift = np.zeros([b_sz])\n",
        "    for i in range(b_sz): #-0.98,.28\n",
        "        if shift[i] < -0.40:\n",
        "            new_shift[i] = np.random.uniform(0.65,1.08,1)[0]\n",
        "        #elif shift[i] > -0.18 and shift[i] < 0.18:\n",
        "        #    p = np.random.uniform(0,1,1)[0]\n",
        "        #    new_shift[i] = (p>0.6)*np.random.uniform(0.15,0.38,1)[0] + (p<0.6)*np.random.uniform(-0.38,-0.18,1)[0]\n",
        "        else:\n",
        "            new_shift[i] = np.random.uniform(-0.58,-0.43,1)[0]\n",
        "    \n",
        "    new_shift = tf.convert_to_tensor(new_shift, dtype=tf.float32)\n",
        "    \n",
        "    return new_shift"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SO0-ozk6PKKV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# input pipeline\n",
        "def refocus(lightfield, b_sz, shift_tf=None):\n",
        "    if shift_tf is None:\n",
        "        shift = np.zeros([b_sz])\n",
        "        for i in range(b_sz):\n",
        "            p = np.random.uniform(0,1,1)[0]\n",
        "            if p<0.851:\n",
        "                val = np.random.uniform(-0.55,-0.08,1)[0]\n",
        "            else:\n",
        "                val = np.random.uniform(0.04,0.15,1)[0]\n",
        "            shift[i] = val\n",
        "        shift_tf = tf.convert_to_tensor(shift, dtype=tf.float32 )\n",
        "    else:\n",
        "        shift = [None]*b_sz\n",
        "\n",
        "    #shift = tf.stack(shift)\n",
        "    #shift = tf.convert_to_tensor(shift, dtype=tf.float32 )\n",
        "    shift_tf = tf.reshape(shift_tf, [b_sz,1,1,1,1])\n",
        "        \n",
        "    lfr = refocus_lf(lightfield[:,:,:,:,:,0], shift_tf, b_sz)\n",
        "    lfg = refocus_lf(lightfield[:,:,:,:,:,1], shift_tf, b_sz)\n",
        "    lfb = refocus_lf(lightfield[:,:,:,:,:,2], shift_tf, b_sz)\n",
        "    \n",
        "    lf_refocus = tf.stack([lfr, lfg, lfb], axis=5)\n",
        "    return lf_refocus, shift\n",
        "\n",
        "def process_lf(lf, num_crops, lfsize, patchsize, prob_refocus):\n",
        "    vsz = 8\n",
        "    usz = 8\n",
        "    \n",
        "    lf = tf.to_float(lf[:lfsize[0]*14, :lfsize[1]*14, :])/65535.0\n",
        "    \n",
        "    lf = tf.image.rgb_to_hsv(tf.pow(lf, 1/1.5))\n",
        "    lf = tf.concat([lf[:,:,0:1],lf[:,:,1:2]*1.5,lf[:,:,2:3]],axis=2)\n",
        "    lf = tf.image.hsv_to_rgb(lf)\n",
        "    lf = tf.clip_by_value(lf, 0.0,1.0)\n",
        "    \n",
        "    lf = normalize_lf(lf)\n",
        "    lf = tf.transpose(tf.reshape(lf, [lfsize[0], 14, lfsize[1], 14, 3]), [0, 2, 1, 3, 4], name='process')\n",
        "    lf = lf[:, :, (14/2)-(vsz/2):(14/2)+(vsz/2), (14/2)-(usz/2):(14/2)+(usz/2), :]\n",
        "    \n",
        "    \n",
        "    #print lf.get_shape()\n",
        "    su = np.random.randint(0,2,1)[0]\n",
        "    sv = np.random.randint(0,2,1)[0]\n",
        "    lf = lf[:,:,su:su+lfsize[2],sv:sv+lfsize[3],:] # extracts random LFs of angular res 7x7\n",
        "    \n",
        "    aif = lf[:, :, lfsize[2]/2, lfsize[3]/2, :]\n",
        "    aif_list = []\n",
        "    lf_list = []\n",
        "    shift_list = []\n",
        "    for i in range(num_crops):\n",
        "        r = tf.random_uniform(shape=[], minval=0, maxval=tf.shape(lf)[0]-patchsize[0], dtype=tf.int32)\n",
        "        c = tf.random_uniform(shape=[], minval=0, maxval=tf.shape(lf)[1]-patchsize[1], dtype=tf.int32)\n",
        "        \n",
        "        prefocus = np.random.uniform(0,1,1)[0]\n",
        "        #print 'check', prefocus, prob_refocus\n",
        "        if(prefocus < prob_refocus):\n",
        "            r = tf.random_uniform(shape=[], minval=0, maxval=tf.shape(lf)[0]-patchsize[0]-20, dtype=tf.int32)\n",
        "            c = tf.random_uniform(shape=[], minval=0, maxval=tf.shape(lf)[1]-patchsize[1]-20, dtype=tf.int32)\n",
        "            patch_lf = lf[r:r+patchsize[0]+20, c:c+patchsize[1]+20, :, :, :]\n",
        "            \n",
        "            ref_patch_lf, shift = refocus(tf.expand_dims(patch_lf,0), 1)\n",
        "            ref_patch_lf = tf.squeeze(ref_patch_lf)\n",
        "            \n",
        "            new_shift = get_rival_shifts(shift)       \n",
        "            \n",
        "            #print tf.shape(new_shift)\n",
        "            lf_list.append(ref_patch_lf[10:-10, 10:-10, :, :, :])#shift_val[idx]\n",
        "            aif_list.append(ref_patch_lf[10:-10, 10:-10, lfsize[2]/2, lfsize[3]/2, :])\n",
        "            shift_list.append(new_shift)\n",
        "        else:\n",
        "            lf_list.append(lf[r:r+patchsize[0], c:c+patchsize[1], :, :, :])\n",
        "            aif_list.append(aif[r:r+patchsize[0], c:c+patchsize[1], :])\n",
        "            \n",
        "            shift_list.append(tf.convert_to_tensor([-0.61], dtype=tf.float32 ))\n",
        "            \n",
        "    return aif_list, lf_list, shift_list\n",
        "\n",
        "def read_lf(filename_queue, num_crops, lfsize, Test, patchsize, prob_refocus):\n",
        "    value = tf.read_file(filename_queue[0])\n",
        "    lf = tf.image.decode_png(value, channels=3, dtype=tf.uint16)\n",
        "    aif_list, lf_list, shift_list = process_lf(lf, num_crops, lfsize, patchsize, prob_refocus)\n",
        "    return aif_list, lf_list, shift_list\n",
        "\n",
        "def input_pipeline(filenames, lfsize, patchsize, batchsize, num_crops, m, n, c, prob_refocus, Test=False):\n",
        "    filename_queue = tf.train.slice_input_producer([filenames], shuffle=True)\n",
        "    example_list = [read_lf(filename_queue, num_crops, lfsize, Test, patchsize, prob_refocus) for _ in range(n)] #number of threads for populating queue\n",
        "    min_after_dequeue = m\n",
        "    capacity = c\n",
        "    aif_batch, lf_batch, shift_list = tf.train.shuffle_batch_join(example_list, batch_size=batchsize, capacity=capacity, \n",
        "                                                      min_after_dequeue=min_after_dequeue, enqueue_many=True,\n",
        "                                                      shapes=[[patchsize[0], patchsize[1], 3], \n",
        "                                                              [patchsize[0], patchsize[1], lfsize[2], lfsize[3], 3], \n",
        "                                                              [1]])\n",
        "    return aif_batch, lf_batch, shift_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDdRnMAlt1Gz",
        "colab_type": "text"
      },
      "source": [
        "###  **Loading light field data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OL80TfU6PKKX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#path to training examples\n",
        "train_path = '/media/flash/ExTra/ulf_focdef/data/TrainingSet/OURS/' \n",
        "train_filenames = [os.path.join(train_path, f) for f in os.listdir(train_path) if not f.startswith('.')]\n",
        "\n",
        "#path to validation examples\n",
        "val_path2 = '/media/flash/ExTra/ulf_focdef/data/TestSet/PAPER/'\n",
        "val_path = '/media/flash/ExTra/ulf_focdef/data/TestSet/EXTRA/'\n",
        "\n",
        "val_filenames = [os.path.join(val_path, f) for f in os.listdir(val_path) if not f.startswith('.')]\n",
        "val_filenames2 = [os.path.join(val_path2, f) for f in os.listdir(val_path2) if not f.startswith('.')]\n",
        "\n",
        "val_filenames = val_filenames + val_filenames2\n",
        "\n",
        "#loading light field data from files\n",
        "aif_batch, lf_batch, shear_values = input_pipeline(train_filenames, lfsize, patchsize, batchsize, num_crops, m=30,n=5, c=88, prob_refocus=.15)\n",
        "vaif_batch, vlf_batch, vshear_values = input_pipeline(val_filenames, lfsize, test_patchsize, test_batchsize, test_num_crops,\n",
        "                                                      m=0,n=2, c=10, prob_refocus=0.0011)\n",
        "\n",
        "is_training = tf.placeholder(tf.bool, [])\n",
        "#shear_values = tf.placeholder(tf.float32, [batchsize])\n",
        "lr = tf.placeholder(tf.float32) #learning rate"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Whs3ui-t_e9",
        "colab_type": "text"
      },
      "source": [
        "###  **Forward pass of the pipeline**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EEOUE20PKKZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "blur_code = tf.convert_to_tensor(blur_code, dtype=tf.float32)\n",
        "test_code = tf.convert_to_tensor(test_code, dtype=tf.float32)\n",
        "\n",
        "#geenrating defocused images from blur code\n",
        "lfc = tf.reduce_sum(lf_batch*blur_code, [-2, -3])\n",
        "vlfc = tf.reduce_sum(vlf_batch*test_code, [-2, -3])\n",
        "\n",
        "#forward pass of the pipeline\n",
        "ray_depths, lf_shear, y, lf_ref, lf_shear_ref = forward_model(aif_batch, lfc, lf_batch, lfsize, \n",
        "                                                              shear_values, disp_mult, is_training)\n",
        "\n",
        "vray_depths, vlf_shear, vy, _, _ = forward_model(vaif_batch, vlfc, vlf_batch, lfsize, \n",
        "                                                 vshear_values, disp_mult, is_training)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjKIEExduJDl",
        "colab_type": "text"
      },
      "source": [
        "###  **Losses**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CcWDu5vqPKKc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#training losses to minimize\n",
        "lam_tv = 0.01\n",
        "lam_dc = 0.0065\n",
        "lam_gr = 0.01\n",
        "with tf.name_scope('loss'):\n",
        "    shear_loss = tf.reduce_mean(tf.abs(lf_shear-lf_batch))\n",
        "    ref_loss = tf.reduce_mean(tf.abs(lf_shear_ref-lf_ref))\n",
        "    output_loss = tf.reduce_mean(tf.abs(y-lf_batch)) \n",
        "\n",
        "    tv_loss = lam_tv *fn_tv_loss(ray_depths)\n",
        "    grad_loss = lam_gr * fn_grad_loss(ray_depths, lf_batch)\n",
        "    \n",
        "    depth_consistency_loss = lam_dc * fn_depth_consistency_loss(ray_depths, lfsize)\n",
        "    \n",
        "    regu_loss = tv_loss + depth_consistency_loss + grad_loss + ref_loss\n",
        "    train_loss =  shear_loss +  output_loss + regu_loss\n",
        "\n",
        "with tf.name_scope('vloss'):\n",
        "    vshear_loss = tf.reduce_mean(tf.abs(vlf_shear-vlf_batch))\n",
        "    voutput_loss = tf.reduce_mean(tf.abs(vy-vlf_batch)) \n",
        "    val_loss = vshear_loss + voutput_loss\n",
        "    \n",
        "with tf.name_scope('train'):\n",
        "    train_step = tf.train.AdamOptimizer(learning_rate=lr).minimize(train_loss)    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NOag4JquLsh",
        "colab_type": "text"
      },
      "source": [
        "###  **Generating summaries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64SAZoc1PKKe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corner1 = tf.convert_to_tensor(np.array([0,0,6,6]).reshape(-1,1), dtype=tf.int32)\n",
        "corner2 = tf.convert_to_tensor(np.array([0,6,0,6]).reshape(-1,1), dtype=tf.int32)\n",
        "\n",
        "corner_rays = get_corners(tf.expand_dims(ray_depths,5))\n",
        "corner_lfbatch = get_corners(lf_batch)\n",
        "corner_lfshear = get_corners(lf_shear)\n",
        "corner_lfy = get_corners(y)\n",
        "\n",
        "#tensorboard summaries\n",
        "tf.summary.scalar('shear_loss', shear_loss)\n",
        "tf.summary.scalar('ref_loss', ref_loss)\n",
        "tf.summary.scalar('output_loss', output_loss)\n",
        "tf.summary.scalar('tv_loss', tv_loss)\n",
        "tf.summary.scalar('grd_loss', grad_loss)\n",
        "tf.summary.scalar('depth_consistency_loss', depth_consistency_loss)\n",
        "tf.summary.scalar('train_loss', train_loss)\n",
        "\n",
        "tf.summary.histogram('ray_depths', ray_depths)\n",
        "tf.summary.histogram('shear_vals', shear_values)\n",
        "tf.summary.image('input_image', aif_batch[0:2,:,:,:])\n",
        "tf.summary.image('coded_image', tf.reduce_sum(lf_batch[0:2,:,:,:,:,:]*defocus_code, [-2, -3]))\n",
        "tf.summary.image('disp_image', tf.reshape(tf.clip_by_value(ray_depths[0:2,:,:,3,3],-1.25,1.25), [2,patchsize[0],patchsize[1],1]))\n",
        "\n",
        "\n",
        "tf.summary.image('lf_rays', tf.reshape(tf.transpose(corner_rays[0:2, ...], perm=[0, 3, 1, 4, 2]), \n",
        "                                        [2, patchsize[0]*2, patchsize[1]*2, 1]))\n",
        "tf.summary.image('lf_gt', tf.reshape(tf.transpose(corner_lfbatch[0:2, ...], perm=[0, 3, 1, 4, 2, 5]), \n",
        "                                        [2, patchsize[0]*2, patchsize[1]*2, 3]))\n",
        "tf.summary.image('lf_shear', tf.reshape(tf.transpose(corner_lfshear[0:2, ...], perm=[0, 3, 1, 4, 2, 5]), \n",
        "                                        [2, patchsize[0]*2, patchsize[1]*2, 3]))\n",
        "tf.summary.image('lf_y', tf.reshape(tf.transpose(corner_lfy[0:2, ...], perm=[0, 3, 1, 4, 2, 5]), \n",
        "                                        [2, patchsize[0]*2, patchsize[1]*2, 3]))\n",
        "\n",
        "merged = tf.summary.merge_all()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Xa5C7D4uRov",
        "colab_type": "text"
      },
      "source": [
        "###  **Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "nvErTezUPKKg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logdir = '/media/flash/ExTra/ulf_focdef/logs/' #path to store logs\n",
        "checkpointdir = '/media/flash/ExTra/ulf_focdef/logs/ckpt/' #path to store checkpoints\n",
        "vf = '/media/flash/ExTra/ulf_focdef/logs/val_results.txt' #path to store validation loss\n",
        "\n",
        "fid = open(vf,'a')\n",
        "fid.write(str(.3)+'\\n')\n",
        "fid.close()\n",
        "\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth=True\n",
        "\n",
        "with tf.Session(config=config) as sess:\n",
        "    train_writer = tf.summary.FileWriter(logdir, sess.graph)\n",
        "    sess.run(tf.global_variables_initializer()) #initialize variables (comment out if restoring from trained model)\n",
        "    \n",
        "    saver = tf.train.Saver()\n",
        "    #saver.restore(sess, '/media/data/susmitha/ucsd/dila_defgtcv/checkpoints/2-occ/hsv_occ/model.ckpt-1999') # restore trained model\n",
        "    #saver = tf.train.Saver()\n",
        "\n",
        "    print('training')\n",
        "    coord = tf.train.Coordinator() #coordinator for input queue threads\n",
        "    threads = tf.train.start_queue_runners(sess=sess, coord=coord) #start input queue threads\n",
        "    for i in range(train_iters):\n",
        "        \n",
        "        #training training stepgi\n",
        "        tloss = sess.run([shear_loss, output_loss, train_step], \n",
        "                         feed_dict={is_training:True, lr:learning_rate}) #shear_values:shear_vals, \n",
        "        \n",
        "        if (i+1) % 50 == 0:\n",
        "            print i, tloss[0], tloss[1], tloss[1]/tloss[0]\n",
        "                \n",
        "        #save training summaries\n",
        "        if (i+1) % 50 == 0: #can change the frequency of writing summaries for faster training\n",
        "            trainsummary = sess.run(merged, feed_dict={is_training:True}) #shear_values:shear_vals\n",
        "            train_writer.add_summary(trainsummary, i)  \n",
        "            \n",
        "        #save checkpoint\n",
        "        if (i+1) % 500 == 0:\n",
        "            saver.save(sess, checkpointdir + 'model.ckpt', global_step=i)\n",
        "            \n",
        "        \n",
        "        if (i+1) % 1000 == 0:\n",
        "            print 'testing'\n",
        "            vloss = []\n",
        "            sloss = []\n",
        "            oloss = []\n",
        "            for j in range(160):\n",
        "                print j, \n",
        "                vl = sess.run([val_loss, vshear_loss, voutput_loss], feed_dict={is_training:False})\n",
        "                vloss.append(vl[0])\n",
        "                sloss.append(vl[1])\n",
        "                oloss.append(vl[2])\n",
        "            print \n",
        "            vloss = np.array(vloss)\n",
        "            sloss = np.array(sloss)\n",
        "            oloss = np.array(oloss)\n",
        "            print np.mean(sloss), np.mean(vloss), np.mean(oloss)\n",
        "            fid = open(vf,'a')\n",
        "            fid.write(str(vloss.mean()) + ' '+ str(np.array(sloss).mean()) + ' ' + str(np.array(oloss).mean()) + '\\n')\n",
        "            fid.close()\n",
        "\n",
        "    #cleanup\n",
        "    train_writer.close()\n",
        "    coord.request_stop()\n",
        "    coord.join(threads)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}